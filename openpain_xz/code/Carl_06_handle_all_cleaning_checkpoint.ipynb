{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a739523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install load_confounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nilearn\n",
    "import nibabel as nb\n",
    "\n",
    "from nilearn.datasets import load_mni152_template\n",
    "from nilearn.image import resample_to_img, load_img\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from nilearn.glm.first_level import FirstLevelModel, make_first_level_design_matrix\n",
    "from nilearn import image, masking, plotting, maskers\n",
    "\n",
    "#from load_resp_stim import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "template = load_mni152_template()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98c2ff69",
   "metadata": {},
   "source": [
    "### taken from trash/12_file_analysis_before_svm.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43658bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def just_check_output_folder():\n",
    "    parent_dir = \"output/\"\n",
    "    subjects_to_not_consider = []\n",
    "    for subject_dir in sorted(os.listdir(parent_dir)):\n",
    "        subject_dir_path = os.path.join(parent_dir, subject_dir)\n",
    "        if os.path.isdir(subject_dir_path) and \"sub\" in subject_dir_path:\n",
    "            count = 0\n",
    "            for visit_dir in sorted(os.listdir(subject_dir_path)):\n",
    "                visit_dir_path = os.path.join(subject_dir_path, visit_dir)\n",
    "                if os.path.isdir(visit_dir_path) and \"ses\" in visit_dir_path:\n",
    "                    print(visit_dir_path)\n",
    "                    count += 1\n",
    "            if count < 4:\n",
    "                subjects_to_not_consider.append(visit_dir_path.split(\"/\")[1].split(\"-\")[1])\n",
    "            print(\"\")\n",
    "    return subjects_to_not_consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6693b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_to_not_consider = just_check_output_folder() \n",
    "# this checks if all of the visits are in the output folder. If not, then the subject is not considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subjects_to_not_consider) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd242b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject_sessions(subjects_to_not_consider):\n",
    "    \"\"\"This loads sessions from all subjects (everything in output), except the ones that are not to be considered.\"\"\"\n",
    "\n",
    "    parent_dir = \"output/\"\n",
    "    \n",
    "    subject_sessions = []\n",
    "    for subject_dir in sorted(os.listdir(parent_dir)): # for each subject\n",
    "        subject_dir_path = os.path.join(parent_dir, subject_dir) # get the path to the subject directory\n",
    "        if os.path.isdir(subject_dir_path) and \"sub\" in subject_dir_path:  # make sure it's actually a subject directory, and that it's a directory\n",
    "            for visit_dir in sorted(os.listdir(subject_dir_path)): # for every visit\n",
    "                visit_dir_path = os.path.join(subject_dir_path, visit_dir) # get the path to the visit directory\n",
    "                if os.path.isdir(visit_dir_path) and \"ses\" in visit_dir_path: # check it's a visit, and also check that it's a directory\n",
    "                    if not any(subject_id in visit_dir_path for subject_id in subjects_to_not_consider): # if this is a subject to consider\n",
    "                        subject_sessions.append(visit_dir_path) # then append it to the subject sessions list\n",
    "    return subject_sessions\n",
    "\n",
    "def load_subject_files(subject_sessions):\n",
    "    df = pd.DataFrame()\n",
    "    for session_dir in sorted(subject_sessions):\n",
    "        dict_for_subject = {\"subject\": str(session_dir.split(\"/\")[1][4:]), \"session\": str(session_dir.split(\"/\")[2][-1])}\n",
    "        for file in sorted(os.listdir(session_dir + \"/func/\")):\n",
    "            if \"confounds\" in file:\n",
    "                complete_file_path = os.path.join(session_dir + \"/func/\", file)\n",
    "                if \"mv\" in file in file:\n",
    "                    dict_for_subject[\"mv_confounds\"] = complete_file_path\n",
    "                elif \"sp_run-01\" in file:\n",
    "                    dict_for_subject[\"sp_run_01_confounds\"] = complete_file_path\n",
    "                elif \"sp_run-02\" in file:\n",
    "                    dict_for_subject[\"sp_run_02_confounds\"] = complete_file_path\n",
    "                elif \"sv\" in file:\n",
    "                    dict_for_subject[\"sv_confounds\"] = complete_file_path\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            if \"nii.gz\" in file:\n",
    "                complete_file_path = os.path.join(session_dir + \"/func/\", file)\n",
    "                if \"mv\" in file and \"brain_mask\" in file:\n",
    "                    dict_for_subject[\"mv_brain_mask\"] = complete_file_path\n",
    "                elif \"sp_run-01\" in file and \"brain_mask\" in file:\n",
    "                    dict_for_subject[\"sp_run_01_brain_mask\"] = complete_file_path\n",
    "                elif \"sp_run-02\" in file and \"brain_mask\" in file:\n",
    "                    dict_for_subject[\"sp_run_02_brain_mask\"] = complete_file_path\n",
    "                elif \"sv\" in file and \"brain_mask\" in file:\n",
    "                    dict_for_subject[\"sv_brain_mask\"] = complete_file_path\n",
    "                elif \"mv\" in file and \"desc-preproc_bold\" in file:\n",
    "                    dict_for_subject[\"mv_bold\"] = complete_file_path\n",
    "                elif \"sp_run-01\" in file and \"desc-preproc_bold\" in file:\n",
    "                    dict_for_subject[\"sp_run_01_bold\"] = complete_file_path\n",
    "                elif \"sp_run-02\" in file and \"desc-preproc_bold\" in file:\n",
    "                    dict_for_subject[\"sp_run_02_bold\"] = complete_file_path\n",
    "                elif \"sv\" in file and \"desc-preproc_bold\" in file:\n",
    "                    dict_for_subject[\"sv_bold\"] = complete_file_path\n",
    "                else:\n",
    "                    pass\n",
    "        new_row = pd.Series(dict_for_subject)\n",
    "        df = pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ae887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_sessions = load_subject_sessions(subjects_to_not_consider)\n",
    "subject_files_df = load_subject_files(subject_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0589794",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files_df # this is all the files, for all the subjects that we are considering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20166a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files_df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e685188",
   "metadata": {},
   "source": [
    "The below code shows that one of the subjects is missing mv files. This means that for analysis involving the mv task, we must remove this participant. However, for the sp task, a different set of patients should be missed out (as we also need the response files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subjects_to_not_consider.extend(subject_files_df.loc[subject_files_df['mv_bold'].isna()].subject.tolist())\n",
    "print(subjects_to_not_consider)\n",
    "subject_sessions = load_subject_sessions(subjects_to_not_consider)\n",
    "subject_files_df = load_subject_files(subject_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290074c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nii_shapes(subject_files_df):\n",
    "    \"\"\"This function checks the shapes of all of the files in the sp_run_01_bold (mv is not relevant)\"\"\"\n",
    "    \n",
    "    sp_bold_files = subject_files_df[\"sp_run_01_bold\"].tolist()\n",
    "    subjects_to_not_consider = []\n",
    "\n",
    "    for file in sp_bold_files:\n",
    "        try:\n",
    "            loaded_data = nb.load(file)\n",
    "            if loaded_data.shape != (57, 68, 65, 244):\n",
    "                print(file, loaded_data.shape)\n",
    "                subjects_to_not_consider.append(file.split(\"/\")[1].split(\"-\")[1])\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            print(f\"file: {file}\")\n",
    "    return list(set(subjects_to_not_consider))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e81be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_with_different_file_size = check_nii_shapes(subject_files_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7358c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_to_not_consider.extend(subjects_with_different_file_size)\n",
    "print(subjects_to_not_consider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7fdf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis from the file:\n",
    "# 099 -> 2,3,4 sessions not present\n",
    "# 104 -> 2,3,4 sessions not present\n",
    "# 121 -> 4 session not present\n",
    "# Reject subject 114, mv not available\n",
    "# Reject sp_run_02, not available in most files\n",
    "# Reject subject 098, some problems in the shape of output/sub-098/ses-visit4/func/sub-098_ses-visit4_task-sp_run-01_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz (57, 68, 60, 244)\n",
    "# 098 isn't of shape (57, 68, 65, 244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8694622",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_sessions = load_subject_sessions(subjects_to_not_consider)\n",
    "subject_files_df = load_subject_files(subject_sessions)\n",
    "#subject_files_df.to_excel(\"subject_files.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dcca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files_df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "750a637a",
   "metadata": {},
   "source": [
    "Clean files before creating model\n",
    "\n",
    "https://brainhack-princeton.github.io/handbook/content_pages/05-01-univariate.html\n",
    "\n",
    "https://github.com/davide-aloi/raindrop_analyses_fmri_eeg/blob/a2de41fb6057a73f4eb029c301fcff00710c5157/fmri/preprocessing/resting-state/rs_preprocessing_part_2.ipynb\n",
    "\n",
    "https://nilearn.github.io/dev/auto_examples/04_glm_first_level/plot_predictions_residuals.html#sphx-glr-auto-examples-04-glm-first-level-plot-predictions-residuals-py\n",
    "\n",
    "https://carpentries-incubator.github.io/SDC-BIDS-fMRI/05-data-cleaning-with-nilearn/index.html\n",
    "\n",
    "https://neurostars.org/t/fmriprep-appling-ica-aroma-and-other-regressors/919/3\n",
    "\n",
    "https://neurostars.org/t/including-fmriprep-a-comp-cor-components-causes-raw-and-cleaned-data-to-be-anti-correlated/22884\n",
    "\n",
    "https://github.com/danjgale/psyc-917/tree/9ac6414cdb878a18f2db6e9e9a2a8752e64b0c0a\n",
    "\n",
    "IMPORTANT: (an explanation of different confounds) https://fcp-indi.github.io/docs/latest/user/nuisance\n",
    "\n",
    "```\n",
    "six parameters obtained by rigid body correction of head motion, []\n",
    "the whole-brain signal averaged over all voxels of the brain, ['global_signal', 'global_signal_derivative1', 'global_signal_derivative1_power2', 'global_signal_power2']\n",
    "signal from a ventricular ROI and signal from a region centered in the white matter. ['csf', 'csf_derivative1', 'csf_derivative1_power2', 'csf_power2', 'white_matter', 'white_matter_derivative1', 'white_matter_power2', 'white_matter_derivative1_power2', 'csf_wm']\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_images(df):\n",
    "    \"\"\"This function cleans all of the images in the subject dataframe. Once again, mv tasks are not relevant.\n",
    "    It then saves the cleaned images to the output_cleaned directory\"\"\"\n",
    "\n",
    "    clean_images_path_sp_run_01_bold = []\n",
    "    \n",
    "    output_dir = \"output_cleaned/\"\n",
    "    try:\n",
    "        os.mkdir(output_dir)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \"\"\"\"\n",
    "        print(row[\"mv_bold\"])\n",
    "        print(row[\"mv_confounds\"])\n",
    "        \n",
    "        print(row[\"sp_run_01_bold\"])\n",
    "        print(row[\"sp_run_01_confounds\"])\n",
    "        \"\"\"\n",
    "        \n",
    "        folder_output_path = os.path.join(output_dir, os.path.join(*row[\"mv_bold\"].split(\"/\")[1:-1]))\n",
    "        mv_bold_output_path = os.path.join(output_dir, os.path.join(*row[\"mv_bold\"].split(\"/\")[1:]))\n",
    "        sp_run_01_bold_output_path = os.path.join(output_dir, os.path.join(*row[\"sp_run_01_bold\"].split(\"/\")[1:]))\n",
    "        print(folder_output_path, mv_bold_output_path, sp_run_01_bold_output_path, sep=\"\\n\")\n",
    "        \n",
    "        \"\"\"\"\n",
    "        fmri_img = image.clean_img(file, confounds=confounds, detrend=True, standardize=True,\n",
    "                                   low_pass=low_pass, high_pass=high_pass, t_r=t_r)\n",
    "        fmri_img = image.smooth_img(fmri_img, 5.)\n",
    "        fmri_img.to_filename()\n",
    "        \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed3b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"097\"\n",
    "session = \"4\"\n",
    "task = \"sp_run_01\"\n",
    "subject_files_df.loc[(subject_files_df.subject == subject) & (subject_files_df.session == session)][task + \"_bold\"].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files_df.loc[(subject_files_df.subject == subject) & (subject_files_df.session == session)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = \"4\"\n",
    "subject_files_df.loc[(subject_files_df.subject == subject) & (subject_files_df.session == session)][\"sp_run_01_bold\"].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "492dcbd0",
   "metadata": {},
   "source": [
    "## 3/11/22 - Work on creating this:\n",
    "\n",
    "https://nilearn.github.io/stable/auto_examples/04_glm_first_level/plot_predictions_residuals.html#sphx-glr-auto-examples-04-glm-first-level-plot-predictions-residuals-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a544b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_file(subject_id = \"097\", task = \"sp_run_01\", session = \"1\"):\n",
    "    \"\"\"This function runs the preprocessing for one subject, task and session.\"\"\"\n",
    "\n",
    "    from load_confounds import Confounds\n",
    "    \n",
    "    #index the subject_files_df for a subject, taks and session (task uses different syntax here)\n",
    "    bold_file = subject_files_df.loc[(subject_files_df.subject == subject_id) & (subject_files_df.session == session)][task + \"_bold\"].tolist()[0]\n",
    "    mask_file = subject_files_df.loc[(subject_files_df.subject == subject_id) & (subject_files_df.session == session)][task + \"_brain_mask\"].tolist()[0]\n",
    "    \n",
    "    confounds = Confounds(strategy=[\"high_pass\", \"motion\", \"global\", \"wm_csf\"], motion=\"basic\", global_signal=\"basic\", wm_csf=\"basic\").load(bold_file)\n",
    "    print(confounds.shape)\n",
    "    \n",
    "    t_r = 2.5\n",
    "    high_pass= 0.006\n",
    "    low_pass = None\n",
    "    bold_img = nilearn.image.load_img(bold_file)\n",
    "    bold_img = bold_img.slicer[:,:,:,:]\n",
    "    plotting.plot_epi(bold_img.slicer[:, :, :, 50])\n",
    "    confounds_matrix = confounds[:]\n",
    "    cleaned_bold = nilearn.image.clean_img(bold_img, \n",
    "                                              confounds=confounds_matrix, \n",
    "                                              detrend=False, \n",
    "                                              standardize=False, \n",
    "                                              low_pass=low_pass, \n",
    "                                              high_pass=high_pass,\n",
    "                                              ensure_finite=True,\n",
    "                                              mask_img=mask_file,\n",
    "                                              t_r = t_r\n",
    "                                             )\n",
    "    cleaned_bold = nilearn.image.smooth_img(cleaned_bold, fwhm=7)\n",
    "    plotting.plot_epi(cleaned_bold.slicer[:, :, :, 50])\n",
    "    return cleaned_bold, mask_file"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b001dff6",
   "metadata": {},
   "source": [
    "\n",
    "def stim_and_no_stim(subject_id = \"097\", session = \"1\", stat_threshold = 2, cluster_threshold = 1):\n",
    "    # glm for response for stimulus\n",
    "    with_stim, mask_file_with_stim = preprocess_file(subject_id = subject_id, task = \"sp_run_01\", session = session)\n",
    "    without_stim, mask_file_without_stim = preprocess_file(subject_id = subject_id, task = \"mv\", session = session)\n",
    "    downsampled_response_with_stim = load_sp_func(participant_id= subject_id, visit= session, run= 1)\n",
    "    downsampled_response_without_stim = load_mv_func(participant_id= subject_id, visit= session)[0]\n",
    "    with_and_without = image.concat_imgs([with_stim, without_stim])\n",
    "    df_events = pd.DataFrame()\n",
    "    df_events[\"onset\"] = list(range(0, 480))\n",
    "    df_events[\"duration\"] = 1\n",
    "    df_events[\"trial_type\"] = df_events.index.to_series().apply(lambda x: 'stim_on' if x < 240 else 'stim_off')\n",
    "    print(df_events)\n",
    "    design_matrices = make_first_level_design_matrix(df_events.index, df_events, drift_model='polynomial', drift_order=3,\n",
    "        hrf_model=\"glover\")\n",
    "    plot_design_matrix(design_matrices)\n",
    "    fmri_glm = FirstLevelModel(minimize_memory=False, mask_img=mask_file_with_stim)\n",
    "    fmri_glm = fmri_glm.fit(with_and_without, design_matrices=design_matrices)\n",
    "    fmri_img = with_and_without\n",
    "    mean_img = image.mean_img(fmri_img)\n",
    "    z_map = fmri_glm.compute_contrast('stim_on - stim_off')\n",
    "    plotting.plot_stat_map(z_map, bg_img=mean_img, threshold = stat_threshold)\n",
    "    \"\"\"\n",
    "    from nilearn.reporting import get_clusters_table\n",
    "    from nilearn.maskers import NiftiSpheresMasker\n",
    "\n",
    "    table = get_clusters_table(z_map, stat_threshold = stat_threshold, cluster_threshold = cluster_threshold).set_index('Cluster ID', drop=True)\n",
    "    print(table)\n",
    "\n",
    "    # get the 6 largest clusters' max x, y, and z coordinates\n",
    "    coords = table.loc[range(1, 2), ['X', 'Y', 'Z']].values\n",
    "\n",
    "    # extract time series from each coordinate\n",
    "    masker = NiftiSpheresMasker(coords)\n",
    "    real_timeseries = masker.fit_transform(fmri_img)\n",
    "    predicted_timeseries = masker.fit_transform(fmri_glm.predicted[0])\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # colors for each of the clusters\n",
    "    colors = ['blue', 'navy', 'purple', 'magenta', 'olive', 'teal']\n",
    "    # plot the time series and corresponding locations\n",
    "    fig1, axs1 = plt.subplots(2, 4)\n",
    "    for i in range(0, 4):\n",
    "        # plotting time series\n",
    "        axs1[0, i].set_title('Cluster peak {}\\n'.format(coords[i]))\n",
    "        axs1[0, i].plot(real_timeseries[:, i], c=colors[i], lw=2)\n",
    "        axs1[0, i].plot(predicted_timeseries[:, i], c='r', ls='--', lw=2)\n",
    "        axs1[0, i].set_xlabel('Time')\n",
    "        axs1[0, i].set_ylabel('Signal intensity', labelpad=0)\n",
    "        # plotting image below the time series\n",
    "        roi_img = plotting.plot_stat_map(\n",
    "            z_map, cut_coords=[coords[i][2]], threshold=3.1, figure=fig1,\n",
    "            axes=axs1[1, i], display_mode='z', colorbar=False, bg_img=mean_img)\n",
    "        roi_img.add_markers([coords[i]], colors[i], 300)\n",
    "    fig1.set_size_inches(24, 14)\n",
    "    \"\"\"\n",
    "    design_matrix = fmri_glm.design_matrices_[0]\n",
    "    # contrast with a one for \"active\" and zero everywhere else\n",
    "    stim_on = np.array([1 if c == 'stim_on' else 0 for c in design_matrix.columns])\n",
    "    # contrast with a one for \"rest\" and zero everywhere else\n",
    "    stim_off = np.array([1 if c == 'stim_off' else 0 for c in design_matrix.columns])\n",
    "    effects_of_interest = np.vstack((stim_on, stim_off))\n",
    "    # f-test for rest and activity\n",
    "    z_map_ftest = fmri_glm.compute_contrast(effects_of_interest, stat_type='F', output_type='z_score')\n",
    "    plotting.plot_stat_map(z_map_ftest, bg_img=mean_img, threshold = stat_threshold, display_mode='z', cut_coords=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dc4383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_and_low(subject_id = \"097\", session = \"1\", stat_threshold = 2, cluster_threshold = 1):\n",
    "    \"\"\"This function performs a GLM on a single subject, for a single session, using the sp_run-01 task.\n",
    "    It contrasts overall high activation against overall low activation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the sp bold, mask and response\n",
    "    sp_bold, sp_mask_file = preprocess_file(subject_id = subject_id, task = \"sp_run_01\", session = session)\n",
    "    sp_downsampled_response = load_sp_func(participant_id= subject_id, visit= session, run= 1)\n",
    "\n",
    "    # Create a design matrix, from a dataframe\n",
    "    df_events = pd.DataFrame()\n",
    "    df_events[\"modulation\"] = sp_downsampled_response[4:]\n",
    "    df_events[\"onset\"] = df_events.index\n",
    "    df_events[\"duration\"] = 1\n",
    "    modulation_mean = df_events[\"modulation\"].mean()\n",
    "\n",
    "    df_events[\"trial_type\"] = df_events[\"modulation\"].apply(lambda x: 'low' if x < modulation_mean else 'high')\n",
    "\n",
    "    design_matrices = make_first_level_design_matrix(df_events.index, df_events, drift_model='polynomial', drift_order=3, hrf_model=\"glover\")\n",
    "    plot_design_matrix(design_matrices)\n",
    "\n",
    "    # Create the First Level Model\n",
    "    fmri_glm = FirstLevelModel(minimize_memory=False, mask_img=sp_mask_file)\n",
    "    fmri_glm = fmri_glm.fit(sp_bold, design_matrices=design_matrices)\n",
    "    mean_img = image.mean_img(sp_bold)\n",
    "\n",
    "    #compute the contrast, recovering z values\n",
    "    z_map = fmri_glm.compute_contrast('high - low')\n",
    "    plotting.plot_stat_map(z_map, bg_img=mean_img, threshold = stat_threshold)\n",
    "    \n",
    "    design_matrix = fmri_glm.design_matrices_[0]\n",
    "    # contrast with a one for \"active\" and zero everywhere else\n",
    "    high = np.array([1 if c == 'high' else 0 for c in design_matrix.columns])\n",
    "    # contrast with a one for \"rest\" and zero everywhere else\n",
    "    low = np.array([1 if c == 'low' else 0 for c in design_matrix.columns])\n",
    "    effects_of_interest = np.vstack((high, low))\n",
    "    # f-test for rest and activity\n",
    "    z_map_ftest = fmri_glm.compute_contrast(effects_of_interest, stat_type='F', output_type='z_score')\n",
    "    plotting.plot_stat_map(z_map_ftest, bg_img=mean_img, threshold = stat_threshold, display_mode='z', cut_coords=7)\n",
    "\n",
    "def norm(x):\n",
    "    return (x - np.mean(x))/np.std(x)\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def run_modulation_GLM(subject_id = \"100\", session = \"1\", stat_threshold = 2, cluster_threshold = 1):\n",
    "    \"\"\"Runs a GLM to find neural correlates between the filtered responses for a single subject's sp task, for one session.\"\"\"\n",
    "\n",
    "    sp_bold, mask_file_sp = preprocess_file(subject_id = subject_id, task = \"sp_run_01\", session = session)\n",
    "    run  = 'sp_run1'\n",
    "    # TODO: CHANGE THE WAY WE LOAD THE RESPONSES\n",
    "    # Get the filtered responses\n",
    "    filteredResponsePath = os.path.join('Carl_RL_filtered_responses_sp',f'sub-{subject_id}',f'visit{session}',run,'rl_filtered_responses.npz')\n",
    "    filteredResponses = np.load(filteredResponsePath, allow_pickle=True)\n",
    "\n",
    "    # Split out the regressors\n",
    "    RESPONSE_LENGTH = 8784\n",
    "    BURN_IN = 4*36\n",
    "    original_responses = filteredResponses['response_to_filter'][BURN_IN:RESPONSE_LENGTH]\n",
    "    times = np.arange(len(original_responses))\n",
    "    errors = filteredResponses['errors'][BURN_IN:RESPONSE_LENGTH]\n",
    "    expectations = filteredResponses['expectations'][BURN_IN:RESPONSE_LENGTH]\n",
    "\n",
    "    fig, ax = plt.subplots(3,figsize=(20,5))\n",
    "    ax[0].plot(times, original_responses,label = 'original responses')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(times, errors, label = 'errors')\n",
    "    ax[1].legend()\n",
    "    ax[2].plot(times, expectations, label = 'expectations')\n",
    "    ax[2].legend()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # TODO Downsample the responses, work out when the responses should be clipped *before convolution?*\n",
    "    downsampled_original_responses = original_responses[::36]\n",
    "    downsampled_errors = errors[::36]\n",
    "    downsampled_expectations = expectations[::36]\n",
    "    # TODO Ask Flavia whether I should smooth the responses as well, to account for movement inaccuracies from the subject\n",
    "\n",
    "    #convolve the errors\n",
    "    hrf_8784 = nilearn.glm.first_level.glover_hrf(2.5, oversampling=36, onset = 0.0)\n",
    "    convolved_errors = np.convolve(norm(errors),hrf_8784)[:len(errors)][::36].reshape(-1,1)\n",
    "\n",
    "    # No need for this, as the pre and post subsampling convolutions are practically identical\n",
    "    #convolved_expectations = np.convolve(norm(expectations),hrf_8784)[:len(errors)][::36].reshape(-1,1)\n",
    "    \n",
    "\n",
    "    # Create the dataframe # TODO check these\n",
    "    df_events = pd.DataFrame()\n",
    "    df_events[\"modulation\"] = norm(downsampled_original_responses) # TODO check mean centering\n",
    "    df_events[\"onset\"] = np.arange(len(convolved_errors)) * 2.5\n",
    "    df_events[\"duration\"] = 2.5 # this should be TR ( the duration of each event in seconds)\n",
    "    df_events[\"trial_type\"] = 'response' # this should be TR ( the duration of each event in seconds)\n",
    "    design_matrices = make_first_level_design_matrix(\n",
    "        frame_times = df_events.index * 2.5,\n",
    "        events = df_events, \n",
    "        drift_model='polynomial', \n",
    "        drift_order=3, \n",
    "        hrf_model=\"glover\",\n",
    "        add_regs= convolved_errors,\n",
    "        add_reg_names= ['errors']\n",
    "    )\n",
    "\n",
    "    font = 25\n",
    "\n",
    "    fig = plt.figure(figsize = (20,5))\n",
    "    plt.plot(np.arange(len(design_matrices['response'])),norm(design_matrices['response']), label='normalised convolved expectations')\n",
    "    plt.plot(np.arange(len(design_matrices['response'])) ,norm(design_matrices['errors']),label='normalised convolved errors')\n",
    "    plt.plot(np.arange(36*len(design_matrices['response']))/36.0 ,norm(expectations),label='original_response', linewidth = 0.5)\n",
    "    #plt.plot(np.arange(36*len(design_matrices['dummy']))/36.0 ,errors,label='original errors', linewidth = 0.5)\n",
    "    plt.xticks(np.arange(244)[::16],np.array(np.arange(0,244)[::16]*2.5).astype(int),rotation=90,fontsize=font)\n",
    "    plt.yticks(fontsize=font)\n",
    "    plt.xlabel(\"seconds\", fontsize=font)\n",
    "    plt.legend(fontsize=font/2)\n",
    "    plt.ylabel(\"normalised regressor \\n magnitude\", fontsize=font)\n",
    "    plt.suptitle(\"The convolved regressors for use in the GLM\", fontsize=font)\n",
    "    plt.show()\n",
    "\n",
    "    plot_design_matrix(design_matrices)\n",
    "\n",
    "    # Create a first level model with \n",
    "    fmri_glm = FirstLevelModel(minimize_memory=False, mask_img=mask_file_sp)\n",
    "    fmri_glm = fmri_glm.fit(sp_bold, design_matrices=design_matrices)\n",
    "\n",
    "    # something like this\n",
    "    #z_map_ftest = fmri_glm.compute_contrast('errors', stat_type='T', output_type='z_score')\n",
    "\n",
    "    # mean_img = image.mean_img(sp_bold)\n",
    "    # mean_residuals = image.mean_img(fmri_glm.residuals)\n",
    "    # plotting.plot_glass_brain(mean_residuals, colorbar=True)\n",
    "    # plotting.plot_epi(mean_residuals, colorbar=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8758f028",
   "metadata": {},
   "source": [
    "# Change to the GLM for a report plot ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca499d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x - np.mean(x))/np.std(x)\n",
    "\n",
    "def run_modulation_GLM(subject_id = \"100\", session = \"1\", stat_threshold = 2, cluster_threshold = 1):\n",
    "    \"\"\"Runs a GLM to find neural correlates between the filtered responses for a single subject's sp task, for one session.\"\"\"\n",
    "\n",
    "    sp_bold, mask_file_sp = preprocess_file(subject_id = subject_id, task = \"sp_run_01\", session = session)\n",
    "    run  = 'sp_run1'\n",
    "    # TODO: CHANGE THE WAY WE LOAD THE RESPONSES\n",
    "    # Get the filtered responses\n",
    "    filteredResponsePath = os.path.join('Carl_RL_filtered_responses_sp',f'sub-{subject_id}',f'visit{session}',run,'rl_filtered_responses.npz')\n",
    "    filteredResponses = np.load(filteredResponsePath, allow_pickle=True)\n",
    "\n",
    "    # Split out the regressors\n",
    "    RESPONSE_LENGTH = 8784\n",
    "    BURN_IN = 4*36\n",
    "    original_responses = filteredResponses['response_to_filter'][BURN_IN:RESPONSE_LENGTH]\n",
    "    times = np.arange(len(original_responses))\n",
    "    errors = filteredResponses['errors'][BURN_IN:RESPONSE_LENGTH]\n",
    "    expectations = filteredResponses['expectations'][BURN_IN:RESPONSE_LENGTH]\n",
    "\n",
    "    fig, ax = plt.subplots(3,figsize=(20,5))\n",
    "    ax[0].plot(times, original_responses,label = 'original responses')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(times, errors, label = 'errors')\n",
    "    ax[1].legend()\n",
    "    ax[2].plot(times, expectations, label = 'expectations')\n",
    "    ax[2].legend()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # TODO Downsample the responses, work out when the responses should be clipped *before convolution?*\n",
    "    downsampled_original_responses = original_responses[::36]\n",
    "    downsampled_errors = errors[::36]\n",
    "    downsampled_expectations = expectations[::36]\n",
    "    # TODO Ask Flavia whether I should smooth the responses as well, to account for movement inaccuracies from the subject\n",
    "\n",
    "    #convolve the errors\n",
    "    hrf_8784 = nilearn.glm.first_level.glover_hrf(2.5, oversampling=36, onset = 0.0)\n",
    "    convolved_errors = np.convolve(norm(errors),hrf_8784)[:len(errors)][::36].reshape(-1,1)\n",
    "\n",
    "    # No need for this, as the pre and post subsampling convolutions are practically identical\n",
    "    #convolved_expectations = np.convolve(norm(expectations),hrf_8784)[:len(errors)][::36].reshape(-1,1)\n",
    "    \n",
    "\n",
    "    # Create the dataframe # TODO check these\n",
    "    df_events = pd.DataFrame()\n",
    "    df_events[\"modulation\"] = norm(downsampled_original_responses) # TODO check mean centering\n",
    "    df_events[\"onset\"] = np.arange(len(convolved_errors)) * 2.5\n",
    "    df_events[\"duration\"] = 2.5 # this should be TR ( the duration of each event in seconds)\n",
    "    df_events[\"trial_type\"] = 'response' # this should be TR ( the duration of each event in seconds)\n",
    "    design_matrices = make_first_level_design_matrix(\n",
    "        frame_times = df_events.index * 2.5,\n",
    "        events = df_events, \n",
    "        drift_model='polynomial', \n",
    "        drift_order=3, \n",
    "        hrf_model=\"glover\",\n",
    "        add_regs= convolved_errors,\n",
    "        add_reg_names= ['errors']\n",
    "    )\n",
    "\n",
    "    font = 25\n",
    "\n",
    "    fig,axes = plt.subplots(2,1,figsize = (16,5),sharex=True)\n",
    "    ax = axes.flatten()\n",
    "    ax[0].plot(np.arange(len(design_matrices['response'])),norm(design_matrices['response']), label='predictions')\n",
    "    ax[0].plot(np.arange(len(design_matrices['response'])) ,norm(design_matrices['errors']),label='errors')\n",
    "    #ax[1].plot(np.arange(36*len(design_matrices['response']))/36.0 ,norm(expectations),label='original_response')\n",
    "    ax[1].plot(np.arange(36*len(design_matrices['response']))/36.0 ,savgol_filter(norm(expectations),8*36+1,3), label='original_response')\n",
    "\n",
    "    ax[0].tick_params(axis='y', labelsize=font/1.5)\n",
    "    ax[1].tick_params(axis='y', labelsize=font/1.5)\n",
    "    plt.xticks(np.arange(244)[::16],np.array(np.arange(0,244)[::16]*2.5).astype(int),rotation=90,fontsize=font/1.5)\n",
    "\n",
    "    ax[1].legend(fontsize=font/1.75,loc='upper left')\n",
    "    ax[0].legend(fontsize=font/1.75, loc='upper left')\n",
    "    plt.xlabel(\"seconds\", fontsize=font)\n",
    "    fig.add_subplot(111, frameon=False)\n",
    "    # hide tick and tick label of the big axis\n",
    "    plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "    plt.ylabel(\"Normalised \\n magnitude\", fontsize=font)    \n",
    "    plt.suptitle(\"Convolved RL regressors for use in the GLM, and the smoothed pain ratings\", fontsize=font)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plot_design_matrix(design_matrices)\n",
    "\n",
    "    # Create a first level model with \n",
    "    fmri_glm = FirstLevelModel(minimize_memory=False, mask_img=mask_file_sp)\n",
    "    fmri_glm = fmri_glm.fit(sp_bold, design_matrices=design_matrices)\n",
    "\n",
    "    # something like this\n",
    "    #z_map_ftest = fmri_glm.compute_contrast('errors', stat_type='T', output_type='z_score')\n",
    "\n",
    "    # mean_img = image.mean_img(sp_bold)\n",
    "    # mean_residuals = image.mean_img(fmri_glm.residuals)\n",
    "    # plotting.plot_glass_brain(mean_residuals, colorbar=True)\n",
    "    # plotting.plot_epi(mean_residuals, colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f93e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_modulation_GLM()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80996c75",
   "metadata": {},
   "source": [
    "clean_images(subject_files_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1106fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shape_and_affine(object_passed):\n",
    "    if type(object_passed) == str:\n",
    "        img = nb.load(object_passed)\n",
    "    else:\n",
    "        img = object_passed\n",
    "    return img.shape, img.affine\n",
    "\n",
    "def resample_all_data(df):\n",
    "    new_df = df.copy(deep=True)\n",
    "    \n",
    "    sp_run_01_bold_resampled = []\n",
    "    \n",
    "    orginal_shape_sp_run_01_bold = []\n",
    "    resampled_shape_sp_run_01_bold = []\n",
    "    \n",
    "    original_affine_sp_run_01_bold = []\n",
    "    resampled_affine_sp_run_01_bold = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "            print(row[\"sp_run_01_bold\"])\n",
    "\n",
    "            folder_output_path = os.path.join(\"output_resampled/\", os.path.join(*row[\"mv_bold\"].split(\"/\")[1:-1]))\n",
    "            sp_run_01_bold_output_path = os.path.join(\"output_resampled/\", os.path.join(*row[\"sp_run_01_bold\"].split(\"/\")[1:]))\n",
    "\n",
    "            print(folder_output_path, sp_run_01_bold_output_path, sep=\"\\n\")\n",
    "            \n",
    "            try:\n",
    "                os.makedirs(folder_output_path)\n",
    "            except:\n",
    "                pass\n",
    "                        \n",
    "            resampled_sp_run_01_bold = resample_to_img(row[\"sp_run_01_bold\"], template)\n",
    "            resampled_sp_run_01_bold.to_filename(sp_run_01_bold_output_path)\n",
    "            sp_run_01_bold_resampled.append(sp_run_01_bold_output_path)\n",
    "            orginal_shape_sp_run_01_bold.append(load_shape_and_affine(row[\"sp_run_01_bold\"])[0])\n",
    "            original_affine_sp_run_01_bold.append(load_shape_and_affine(row[\"sp_run_01_bold\"])[1])\n",
    "            resampled_shape_sp_run_01_bold.append(load_shape_and_affine(resampled_sp_run_01_bold)[0])\n",
    "            resampled_affine_sp_run_01_bold.append(load_shape_and_affine(resampled_sp_run_01_bold)[1])\n",
    "            \n",
    "    new_df[\"sp_run_01_bold_resampled\"] = sp_run_01_bold_resampled\n",
    "    \n",
    "    new_df[\"orginal_shape_sp_run_01_bold\"] = orginal_shape_sp_run_01_bold\n",
    "    new_df[\"resampled_shape_sp_run_01_bold\"] = resampled_shape_sp_run_01_bold\n",
    "    \n",
    "    new_df[\"original_affine_sp_run_01_bold\"] = original_affine_sp_run_01_bold\n",
    "    new_df[\"resampled_affine_sp_run_01_bold\"] = resampled_affine_sp_run_01_bold\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def resample_all_brain_masks(df):\n",
    "    new_df = df.copy(deep=True)\n",
    "    \n",
    "    sp_run_01_brain_mask_resampled = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        print(row[\"sp_run_01_brain_mask\"])\n",
    "        folder_output_path = os.path.join(\"output_resampled/\", os.path.join(*row[\"mv_brain_mask\"].split(\"/\")[1:-1]))\n",
    "        sp_run_01_brain_mask_output_path = os.path.join(\"output_resampled/\", os.path.join(*row[\"sp_run_01_brain_mask\"].split(\"/\")[1:]))\n",
    "        print(folder_output_path, sp_run_01_brain_mask_output_path)\n",
    "        try:\n",
    "            os.makedirs(folder_output_path)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        resampled_sp_run_01_brain_mask = resample_to_img(row[\"sp_run_01_brain_mask\"], template, interpolation = 'nearest')\n",
    "        resampled_sp_run_01_brain_mask.to_filename(sp_run_01_brain_mask_output_path)\n",
    "        sp_run_01_brain_mask_resampled.append(sp_run_01_brain_mask_output_path)\n",
    "    \n",
    "    new_df[\"sp_run_01_brain_mask_resampled\"] = sp_run_01_brain_mask_resampled\n",
    "    return new_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2801a497de70ae62ab0a80e9b3176302dc762b9ebe33dfeb141390422f5fa02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
